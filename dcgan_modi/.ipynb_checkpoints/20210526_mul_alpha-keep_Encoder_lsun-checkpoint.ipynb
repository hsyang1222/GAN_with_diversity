{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e271bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [on]\n",
      "Loading model from: /opt/conda/envs/stylegan2/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "{'dataset': 'lsun_churchs', 'dataroot': '../../../20210317_MLVU/lsun/dataset/', 'workers': 4, 'batchSize': 2048, 'imageSize': 32, 'nz': 100, 'ngf': 64, 'ndf': 64, 'niter': 500, 'lr': 0.0002, 'beta1': 0.5, 'cuda': True, 'dry_run': False, 'ngpu': 1, 'netG': '', 'netD': '', 'netE': '', 'manualSeed': None, 'classes': None, 'outf': 'result_image', 'AEiter': 10, 'z_add': 0.8, 'lambda_diverse': 0.0, 'lambda_uniform': 0, 'try_div_chance': 0, 'device': 'cuda:2', 'name': 'keepEG', 'report_every': 10, 'keep_try_over': 0.8, 'mul_alpha_param': 0.06}\n",
      "Random Seed:  2605\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown value 'churcs_outdoor' for LSUN class. Valid values are {'bedroom', 'bridge', 'church_outdoor', 'classroom', 'conference_room', 'dining_room', 'kitchen', 'living_room', 'restaurant', 'tower'}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.9.0/torchvision/datasets/lsun.py\u001b[0m in \u001b[0;36m_verify_classes\u001b[0;34m(self, classes)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.9.0/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mverify_str_arg\u001b[0;34m(value, arg, valid_values, custom_msg)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected type str for argument classes, but got type <class 'list'>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-417b0fceb8ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lsun_churchs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'churcs_outdoor_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     dataset = dset.LSUN(root=opt.dataroot, classes=classes,\n\u001b[0m\u001b[1;32m     92\u001b[0m                         transform=transforms.Compose([\n\u001b[1;32m     93\u001b[0m                             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimageSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.9.0/torchvision/datasets/lsun.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, classes, transform, target_transform)\u001b[0m\n\u001b[1;32m     78\u001b[0m         super(LSUN, self).__init__(root, transform=transform,\n\u001b[1;32m     79\u001b[0m                                    target_transform=target_transform)\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# for each class, create an LSUNClassDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.9.0/torchvision/datasets/lsun.py\u001b[0m in \u001b[0;36m_verify_classes\u001b[0;34m(self, classes)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 msg = msg_fmtstr.format(category, \"LSUN class\",\n\u001b[1;32m    126\u001b[0m                                         iterable_to_str(categories))\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg_fmtstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"postfix\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_vision_v0.9.0/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mverify_str_arg\u001b[0;34m(value, arg, valid_values, custom_msg)\u001b[0m\n\u001b[1;32m    348\u001b[0m             msg = msg.format(value=value, arg=arg,\n\u001b[1;32m    349\u001b[0m                              valid_values=iterable_to_str(valid_values))\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown value 'churcs_outdoor' for LSUN class. Valid values are {'bedroom', 'bridge', 'church_outdoor', 'classroom', 'conference_room', 'dining_room', 'kitchen', 'living_room', 'restaurant', 'tower'}."
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import generative_model_score\n",
    "inception_model_score = generative_model_score.GenerativeModelScore()\n",
    "inception_model_score.lazy_mode(True)\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import lpips\n",
    "\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "    'dataset':'lsun_churchs',\n",
    "    'dataroot':'../../../20210317_MLVU/lsun/dataset/',\n",
    "    'workers':4,\n",
    "    'batchSize':2048,\n",
    "    'imageSize':32,\n",
    "    'nz':100,\n",
    "    'ngf':64,\n",
    "    'ndf':64,\n",
    "    'niter':500,\n",
    "    'lr':0.0002,\n",
    "    'beta1':0.5,\n",
    "    'cuda':True,\n",
    "    'dry_run':False,\n",
    "    'ngpu':1,\n",
    "    'netG':'',\n",
    "    'netD':'',\n",
    "    'netE':'',\n",
    "    'manualSeed':None,\n",
    "    'classes':None,\n",
    "    'outf':'result_image',\n",
    "    'AEiter' : 10,\n",
    "    'z_add':0.8,\n",
    "    'lambda_diverse': 0.0,\n",
    "    'lambda_uniform' : 0,\n",
    "    'try_div_chance' : 0,\n",
    "    'device':'cuda:2',\n",
    "    'name' : 'keepEG',\n",
    "    'report_every' : 10,\n",
    "    'keep_try_over' : 0.8,\n",
    "    'mul_alpha_param' : 0.06\n",
    "})\n",
    "\n",
    "lpips_model = loss_fn = lpips.LPIPS(net='alex', spatial=True)\n",
    "\n",
    "#opt = parser.parse_args()\n",
    "opt = args\n",
    "print(opt)\n",
    "\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "  \n",
    "\n",
    "if opt.dataroot is None and str(opt.dataset).lower() != 'fake':\n",
    "    raise ValueError(\"`dataroot` parameter is required for dataset \\\"%s\\\"\" % opt.dataset)\n",
    "\n",
    "if opt.dataset in ['imagenet', 'folder', 'lfw']:\n",
    "    # folder dataset\n",
    "    dataset = dset.ImageFolder(root=opt.dataroot,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize(opt.imageSize),\n",
    "                                   transforms.CenterCrop(opt.imageSize),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]))\n",
    "    nc=3\n",
    "elif opt.dataset == 'lsun_churchs':\n",
    "    classes = ['church_outdoor_train']\n",
    "    dataset = dset.LSUN(root=opt.dataroot, classes=classes,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.Resize(opt.imageSize),\n",
    "                            transforms.CenterCrop(opt.imageSize),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                        ]))\n",
    "    nc=3\n",
    "elif opt.dataset == 'cifar10':\n",
    "    dataset = dset.CIFAR10(root=opt.dataroot, #download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(opt.imageSize),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "    nc=3\n",
    "\n",
    "elif opt.dataset == 'mnist':\n",
    "        dataset = dset.MNIST(root=opt.dataroot, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(opt.imageSize),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,)),\n",
    "                           ]))\n",
    "        nc=1\n",
    "\n",
    "elif opt.dataset == 'fake':\n",
    "    dataset = dset.FakeData(image_size=(3, opt.imageSize, opt.imageSize),\n",
    "                            transform=transforms.ToTensor())\n",
    "    nc=3\n",
    "    \n",
    "elif opt.dataset == 'celeba':\n",
    "        dataset = dset.CelebA(root=opt.dataroot, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(opt.imageSize),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "        nc=3\n",
    "\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "\n",
    "device = torch.device(opt.device if opt.cuda else \"cpu\")\n",
    "ngpu = int(opt.ngpu)\n",
    "nz = int(opt.nz)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)\n",
    "\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            #nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 2, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 2 x 2\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 16 x 16\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "if opt.netG != '':\n",
    "    netG.load_state_dict(torch.load(opt.netG))\n",
    "print(netG)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            #nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Conv2d(ndf * 8, 1, 2, 1, 0, bias=False),\n",
    "            # state size. 1x1x1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            #nn.Conv2d(ndf * 8, 100, 4, 1, 0, bias=False),\n",
    "            nn.Conv2d(ndf * 8, nz, 2, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "        \n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "if opt.netD != '':\n",
    "    netD.load_state_dict(torch.load(opt.netD))\n",
    "print(netD)\n",
    "\n",
    "netE = Encoder(ngpu).to(device)\n",
    "netE.apply(weights_init)\n",
    "if opt.netE != '':\n",
    "    netE.load_state_dict(torch.load(opt.netE))\n",
    "print(netE)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerE = optim.Adam(netE.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "\n",
    "train_loader = dataloader\n",
    "print(train_loader.dataset)\n",
    "real_images_info_file_name = inception_model_score.trainloaderinfo_to_hashedname(train_loader)\n",
    "real_image_info_path = '../../../inception_model_info/'+real_images_info_file_name\n",
    "\n",
    "if os.path.exists( real_image_info_path) : \n",
    "    print(\"Using exist inception model info from :\",real_image_info_path)\n",
    "    inception_model_score.load_real_images_info(real_image_info_path)\n",
    "else : \n",
    "    inception_model_score.model_to(device)\n",
    "\n",
    "    #put real image\n",
    "    for each_batch in train_loader : \n",
    "        X_train_batch = each_batch[0]\n",
    "        inception_model_score.put_real(X_train_batch)\n",
    "\n",
    "    #generate real images info\n",
    "    inception_model_score.lazy_forward(batch_size=64, device=device, real_forward=True)\n",
    "    inception_model_score.calculate_real_image_statistics()\n",
    "    #save real images info for next experiments\n",
    "    inception_model_score.save_real_images_info(real_image_info_path)\n",
    "    print(\"Save inception model info to :\", real_images_info_file_name)\n",
    "    #offload inception_model\n",
    "    inception_model_score.model_to('cpu')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ce928b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE:  10%|█         | 1/10 [00:08<01:12,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.405822686851025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "AE:  20%|██        | 2/10 [00:13<00:52,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.390060603618622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "AE:  30%|███       | 3/10 [00:19<00:43,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.9315383061766624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "AE:  40%|████      | 4/10 [00:25<00:36,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1.7334851175546646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "AE:  50%|█████     | 5/10 [00:31<00:29,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1.5870299488306046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "AE:  60%|██████    | 6/10 [00:36<00:23,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1.510404009371996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "AE:  70%|███████   | 7/10 [00:42<00:17,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1.4215238094329834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "AE:  80%|████████  | 8/10 [00:48<00:11,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1.3704810924828053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "AE:  90%|█████████ | 9/10 [00:54<00:05,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 1.3289216496050358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE: 100%|██████████| 10/10 [01:00<00:00,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 1.2873291112482548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project='GAN_mul_alpha', name=opt.name, config=opt)\n",
    "config = wandb.config\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "import tqdm\n",
    "for epoch in tqdm.tqdm(range(config.AEiter), desc=\"AE\"):\n",
    "    loss_sum = 0.\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        real_cuda = data[0].to(device)\n",
    "        batch_size = real_cuda.size(0)\n",
    "        \n",
    "        latent_vector = netE(real_cuda)\n",
    "        real_latent_4dim = latent_vector.view(batch_size,nz,1,1)\n",
    "        repaint = netG(real_latent_4dim)\n",
    "        \n",
    "        mse_loss = mse(repaint, real_cuda)\n",
    "        optimizerE.zero_grad()\n",
    "        optimizerG.zero_grad()\n",
    "        mse_loss.backward()\n",
    "        optimizerE.step()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        loss_sum += mse_loss.item()\n",
    "                \n",
    "    print(epoch, loss_sum)\n",
    "    \n",
    "mul_alpha = torch.tensor([0.3], requires_grad=True, device=device)\n",
    "optimizerM = torch.optim.Adam([mul_alpha], lr=0.001) \n",
    "\n",
    "fixed_noise = real_latent_4dim.detach()\n",
    "\n",
    "for epoch in range(opt.niter + 1):\n",
    "    for i, data in enumerate(tqdm.tqdm(dataloader, desc='batch')):\n",
    "        real_cuda = data[0].to(device)\n",
    "        batch_size = real_cuda.size(0)\n",
    "        label = torch.full((batch_size,), real_label,\n",
    "                           dtype=real_cuda.dtype, device=device)\n",
    "        \n",
    "        #############################\n",
    "        # generate original_feature\n",
    "        #############################\n",
    "        latent_vector = netE(real_cuda)\n",
    "        real_latent_4dim = latent_vector.view(batch_size,nz,1,1)\n",
    "        repaint = netG(real_latent_4dim)\n",
    "  \n",
    "        mse_loss = mse(repaint, real_cuda)\n",
    "        optimizerE.zero_grad()\n",
    "        optimizerG.zero_grad()\n",
    "        mse_loss.backward()\n",
    "        optimizerE.step()\n",
    "        optimizerG.step()\n",
    "    \n",
    "        real_feature = real_latent_4dim.detach()\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        output_real = netD(real_cuda)\n",
    "        errD_real = criterion(output_real, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output_real.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        sigmoid_mul_alpha = torch.sigmoid(mul_alpha)\n",
    "        real_feature_noised  = (1-sigmoid_mul_alpha)*real_feature + sigmoid_mul_alpha*noise\n",
    "        \n",
    "        repaint_real = netG(real_feature)\n",
    "        fake = netG(real_feature_noised.detach())\n",
    "        \n",
    "        if config.report_every > 0 and epoch % config.report_every == 0 :\n",
    "            inception_model_score.put_fake(fake.detach().cpu())\n",
    "        \n",
    "        label.fill_(fake_label)\n",
    "        output_repaint_real = netD(repaint_real)\n",
    "        output_fake = netD(fake)\n",
    "        errD_fake = criterion(output_fake, label) + criterion(output_repaint_real, label)\n",
    "        D_G_z1 = output_fake.mean().item()\n",
    "        errD_fake.backward()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        \n",
    "        sigmoid_mul_alpha = torch.sigmoid(mul_alpha)\n",
    "        real_feature_noised  = (1-sigmoid_mul_alpha)*real_feature + sigmoid_mul_alpha*noise\n",
    "        repaint_real = netG(real_feature)\n",
    "        fake = netG(real_feature_noised)\n",
    "\n",
    "        maximize_diff = torch.mean(torch.abs(repaint_real - fake))\n",
    "\n",
    "        output_fake = netD(fake)\n",
    "        output_repaint_real = netD(repaint_real)\n",
    "\n",
    "        maximize_output_fake = torch.mean(output_repaint_real - output_fake)\n",
    "\n",
    "        mul_alpha_loss = -(config.mul_alpha_param * maximize_diff + maximize_output_fake)\n",
    "        optimizerM.zero_grad()\n",
    "        mul_alpha_loss.backward(retain_graph = True)\n",
    "        optimizerM.step()\n",
    "        \n",
    "        errG = criterion(output_fake, label) + criterion(output_repaint_real, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output_fake.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "\n",
    "    if config.report_every > 0 and epoch % config.report_every == 0:\n",
    "        fake = netG(fixed_noise)\n",
    "        vutils.save_image(fake.detach(),\n",
    "            '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "            normalize=True)\n",
    "        \n",
    "        real_feature_noised  = (1-sigmoid_mul_alpha)*fixed_noise + sigmoid_mul_alpha*noise\n",
    "        fake2 = netG(real_feature_noised)\n",
    "        vutils.save_image(fake2.detach(),\n",
    "            '%s/fake2_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "            normalize=True)\n",
    "        \n",
    "        fake_np = vutils.make_grid(fake.detach().cpu(), nrow=32).permute(1,2,0).numpy()\n",
    "        fake2_np = vutils.make_grid(fake2.detach().cpu(), nrow=32).permute(1,2,0).numpy()\n",
    "        \n",
    "        netG = netG.to('cpu')\n",
    "        netD = netD.to('cpu')\n",
    "        \n",
    "        lpips_model.to(device)\n",
    "        ex_d = lpips_model.forward(fake, fake2).mean()\n",
    "        lpips_model.to('cpu')\n",
    "        \n",
    "        inception_model_score.model_to(device)\n",
    "\n",
    "        #generate fake images info\n",
    "        inception_model_score.lazy_forward(batch_size=64, device=device, fake_forward=True)\n",
    "        inception_model_score.calculate_fake_image_statistics()\n",
    "        metrics = inception_model_score.calculate_generative_score()\n",
    "        inception_model_score.clear_fake()\n",
    "\n",
    "        #onload all GAN model to cpu and offload inception model to gpu\n",
    "        inception_model_score.model_to('cpu')\n",
    "        netG = netG.to(device)\n",
    "        netD = netD.to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f, maxi-div : %.4f, maxi-D(noise) : %.4f, mul_alph : %.4f'\n",
    "          % (epoch, opt.niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, \\\n",
    "             maximize_diff, maximize_output_fake, sigmoid_mul_alpha))\n",
    "        \n",
    "        print(\"\\t\\tFID : %.4f, IS_f : %.4f, P : %.4f, R : %.4f, D : %.4f, C : %.4f, LPIPS : %.4f\"\n",
    "              %(metrics['fid'], metrics['fake_is'], metrics['precision'], \n",
    "                metrics['recall'], metrics['density'], metrics['coverage'], ex_d))\n",
    "        \n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\" : epoch,\n",
    "            \"Loss_D\": errD.item(),\n",
    "            \"Loss_G\": errG.item(),\n",
    "            \"D(real)\": D_x,\n",
    "            \"D(G(z))-before D train\": D_G_z1,\n",
    "            \"D(G(z))-after D train\": D_G_z2,\n",
    "            \"fid\" : metrics['fid'],\n",
    "            'fake_is':metrics['fake_is'],\n",
    "            \"precision\":metrics['precision'],\n",
    "            \"recall\":metrics['recall'],\n",
    "            \"density\":metrics['density'],\n",
    "            \"coverage\":metrics['coverage'],\n",
    "            \"G(z) \" : [wandb.Image(fake_np, caption='fixed z image')],\n",
    "            \"G(z + div_add) \" : [wandb.Image(fake2_np, caption='fixed z + %.4f' % mul_alpha)],\n",
    "            'LPIPS' : ex_d,\n",
    "            'maxi-div' : maximize_diff,\n",
    "            'maxi-D(noise)' : maximize_output_fake,\n",
    "            'mul_alpha' : sigmoid_mul_alpha\n",
    "        })\n",
    "\n",
    "        if opt.dry_run:\n",
    "            break\n",
    "    # do checkpointing\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        vutils.save_image(fake.detach(),\n",
    "                '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "                normalize=True)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34faa27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3fd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c6edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd605a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62a3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40931638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55626f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10780e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_alpha = torch.tensor([0.1], requires_grad=True, device=device)\n",
    "optimizerM = torch.optim.Adam([mul_alpha], lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34ea4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4976f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 25/25 [00:29<00:00,  1.16s/it]\n",
      "/opt/conda/envs/stylegan2/lib/python3.9/site-packages/torch/nn/functional.py:3502: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate fake images info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [02:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 10000 Num fake: 10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mul_alph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a86a6d6761ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m               \u001b[0mmaxi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdiv\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmul_alph\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0mf\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m           % (epoch, opt.niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, \\\n\u001b[0;32m--> 114\u001b[0;31m              maximize_diff, maximize_output_fake, mul_alph))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         print(\"\\t\\tFID : %.4f, IS_f : %.4f, P : %.4f, R : %.4f, D : %.4f, C : %.4f, LPIPS : %.4f\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mul_alph' is not defined"
     ]
    }
   ],
   "source": [
    "netE.eval()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(opt.niter):\n",
    "    under50z_list = []\n",
    "    for i, data in enumerate(tqdm.tqdm(dataloader, desc='batch')):\n",
    "        real_cuda = data[0].to(device)\n",
    "        batch_size = real_cuda.size(0)\n",
    "        label = torch.full((batch_size,), real_label,\n",
    "                           dtype=real_cuda.dtype, device=device)\n",
    "        \n",
    "        #############################\n",
    "        # generate original_feature\n",
    "        #############################\n",
    "        real_feature = netE(real_cuda).detach().view(batch_size,nz,1,1)\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        output_real = netD(real_cuda)\n",
    "        errD_real = criterion(output_real, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        real_feature_noised  = (1-mul_alpha)*real_feature + mul_alpha*noise\n",
    "        \n",
    "        repaint_real = netG(real_feature)\n",
    "        fake = netG(real_feature_noised)\n",
    "        \n",
    "        if config.report_every > 0 and epoch % config.report_every == 0 :\n",
    "            inception_model_score.put_fake(fake.detach().cpu())\n",
    "        \n",
    "        label.fill_(fake_label)\n",
    "        output_repaint_real = netD(repaint_real)\n",
    "        output_fake = netD(fake)\n",
    "        errD_fake = criterion(output_fake, label) + criterion(output_repaint_real, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        \n",
    "        real_feature_noised  = (1-mul_alpha)*real_feature + mul_alpha*noise\n",
    "        repaint_real = netG(real_feature)\n",
    "        fake = netG(real_feature_noised)\n",
    "\n",
    "        maximize_diff = torch.mean(torch.abs(repaint_real - fake))\n",
    "\n",
    "        output_fake = netD(fake)\n",
    "        output_repaint_real = netD(repaint_real)\n",
    "\n",
    "        maximize_output_fake = torch.mean(output_repaint_real - output_fake)\n",
    "\n",
    "        mul_alpha_loss = -(config.mul_alpha_param * maximize_diff + maximize_output_fake)\n",
    "        optimizerM.zero_grad()\n",
    "        mul_alpha_loss.backward(retain_graph = True)\n",
    "        optimizerM.step()\n",
    "        \n",
    "        errG = criterion(output_fake, label) + criterion(output_repaint_real, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "\n",
    "    if config.report_every > 0 and epoch % config.report_every == 0:\n",
    "        fake = netG(fixed_noise)\n",
    "        vutils.save_image(fake.detach(),\n",
    "            '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "            normalize=True)\n",
    "\n",
    "        fake2 = netG(fixed_noise + config.z_add)\n",
    "        vutils.save_image(fake2.detach(),\n",
    "            '%s/fake2_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "            normalize=True)\n",
    "        \n",
    "        fake_np = vutils.make_grid(fake.detach().cpu(), nrow=32).permute(1,2,0).numpy()\n",
    "        fake2_np = vutils.make_grid(fake2.detach().cpu(), nrow=32).permute(1,2,0).numpy()\n",
    "        \n",
    "        netG = netG.to('cpu')\n",
    "        netD = netD.to('cpu')\n",
    "        \n",
    "        lpips_model.to(device)\n",
    "        ex_d = lpips_model.forward(fake, fake2).mean()\n",
    "        lpips_model.to('cpu')\n",
    "        \n",
    "        inception_model_score.model_to(device)\n",
    "\n",
    "        #generate fake images info\n",
    "        inception_model_score.lazy_forward(batch_size=64, device=device, fake_forward=True)\n",
    "        inception_model_score.calculate_fake_image_statistics()\n",
    "        metrics = inception_model_score.calculate_generative_score()\n",
    "        inception_model_score.clear_fake()\n",
    "\n",
    "        #onload all GAN model to cpu and offload inception model to gpu\n",
    "        inception_model_score.model_to('cpu')\n",
    "        netG = netG.to(device)\n",
    "        netD = netD.to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f, \\\n",
    "              maxi-div : %.4f, maxi-D(noise) : %.4f, mul_alph : %.4f'\n",
    "          % (epoch, opt.niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, \\\n",
    "             maximize_diff, maximize_output_fake, mul_alpha))\n",
    "        \n",
    "        print(\"\\t\\tFID : %.4f, IS_f : %.4f, P : %.4f, R : %.4f, D : %.4f, C : %.4f, LPIPS : %.4f\"\n",
    "              %(metrics['fid'], metrics['fake_is'], metrics['precision'], \n",
    "                metrics['recall'], metrics['density'], metrics['coverage'], ex_d))\n",
    "        \n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\" : epoch,\n",
    "            \"Loss_D\": errD.item(),\n",
    "            \"Loss_G\": errG.item(),\n",
    "            \"D(real)\": D_x,\n",
    "            \"D(G(z))-before D train\": D_G_z1,\n",
    "            \"D(G(z))-after D train\": D_G_z2,\n",
    "            \"fid\" : metrics['fid'],\n",
    "            'fake_is':metrics['fake_is'],\n",
    "            \"precision\":metrics['precision'],\n",
    "            \"recall\":metrics['recall'],\n",
    "            \"density\":metrics['density'],\n",
    "            \"coverage\":metrics['coverage'],\n",
    "            \"G(z) \" : [wandb.Image(fake_np, caption='fixed z image')],\n",
    "            \"G(z + div_add) \" : [wandb.Image(fake2_np, caption='fixed z + 1e-6 image')],\n",
    "            'LPIPS' : ex_d,\n",
    "            'maxi-div' : maximize_diff,\n",
    "            'maxi-D(noise)' : maximize_output_fake,\n",
    "            'mul_alpha' : mul_alpha\n",
    "        })\n",
    "\n",
    "        if opt.dry_run:\n",
    "            break\n",
    "    # do checkpointing\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        vutils.save_image(fake.detach(),\n",
    "                '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "                normalize=True)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842a1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6694b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d3b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6ba71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000][24/25] Loss_D: 2.3120 Loss_G: 5.5256 D(x): 0.6415 D(G(z)): 0.6415 / 0.6415,       maxi-div : 0.0195, maxi-D(noise) : 0.0002, mul_alph : 0.1425\n",
      "\t\tFID : 328.4508, IS_f : 1.5487, P : 0.1826, R : 0.0000, D : 0.0421, C : 0.0016, LPIPS : 0.0085\n"
     ]
    }
   ],
   "source": [
    "print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f, \\\n",
    "      maxi-div : %.4f, maxi-D(noise) : %.4f, mul_alph : %.4f'\n",
    "  % (epoch, opt.niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, \\\n",
    "     maximize_diff, maximize_output_fake, mul_alpha))\n",
    "\n",
    "print(\"\\t\\tFID : %.4f, IS_f : %.4f, P : %.4f, R : %.4f, D : %.4f, C : %.4f, LPIPS : %.4f\"\n",
    "      %(metrics['fid'], metrics['fake_is'], metrics['precision'], \n",
    "        metrics['recall'], metrics['density'], metrics['coverage'], ex_d))\n",
    "\n",
    "\n",
    "wandb.log({\n",
    "    \"epoch\" : epoch,\n",
    "    \"Loss_D\": errD.item(),\n",
    "    \"Loss_G\": errG.item(),\n",
    "    \"D(real)\": D_x,\n",
    "    \"D(G(z))-before D train\": D_G_z1,\n",
    "    \"D(G(z))-after D train\": D_G_z2,\n",
    "    \"fid\" : metrics['fid'],\n",
    "    'fake_is':metrics['fake_is'],\n",
    "    \"precision\":metrics['precision'],\n",
    "    \"recall\":metrics['recall'],\n",
    "    \"density\":metrics['density'],\n",
    "    \"coverage\":metrics['coverage'],\n",
    "    \"G(z) \" : [wandb.Image(fake_np, caption='fixed z image')],\n",
    "    \"G(z + div_add) \" : [wandb.Image(fake2_np, caption='fixed z + 1e-6 image')],\n",
    "    'LPIPS' : ex_d,\n",
    "    'maxi-div' : maximize_diff,\n",
    "    'maxi-D(noise)' : maximize_output_fake,\n",
    "    'mul_alpha' : mul_alpha\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e2960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a4558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1c29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e00932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3d947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf80c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep try: 0.16969999999999996 < 0.8\n",
      "keep try: 1.0 < 0.8 (pass)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/stylegan2/lib/python3.9/site-packages/torch/nn/functional.py:3502: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate fake images info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [02:11<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 10000 Num fake: 10000\n",
      "[0/100][24/25] Loss_D: 0.3245 Loss_G: 0.0071 D(x): 0.8798 D(G(z)): 0.1641 / 0.9929, DivLoss : 0.0106\n",
      "\t\tFID : 429.8828, IS_f : 1.1670, P : 0.0013, R : 0.0000, D : 0.0003, C : 0.0001, LPIPS : 0.0002\n",
      "keep try: 0.0 < 0.8\n",
      "keep try: 1.0 < 0.8 (pass)\n",
      "keep try: 0.0 < 0.8\n",
      "keep try: 0.87942 < 0.8 (pass)\n",
      "keep try: 0.0 < 0.8\n",
      "keep try: 0.81796 < 0.8 (pass)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fd07badc35e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_diverse\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0merrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mD_G_z2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.niter):\n",
    "    under50z_list = []\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label,\n",
    "                           dtype=real_cpu.dtype, device=device)\n",
    "\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        #noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        noise = torch.rand(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        fake2 = netG(noise + config.z_add)\n",
    "        \n",
    "        if config.report_every > 0 and epoch % config.report_every == 0 :\n",
    "            inception_model_score.put_fake(fake.detach().cpu())\n",
    "        \n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        \n",
    "        fake = netG(noise)\n",
    "        fake2 = netG(noise + config.z_add)\n",
    "        \n",
    "        output = netD(fake)\n",
    "        \n",
    "        loss_ds = torch.mean(torch.abs(fake - fake2))\n",
    "        \n",
    "        errG = criterion(output, label) - config.lambda_diverse * loss_ds\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        fake = netG(noise)\n",
    "        output = netD(fake)\n",
    "        condition_under50 = output < 0.5\n",
    "        under50z_list.append( noise[condition_under50].detach().cpu() )\n",
    "        \n",
    "    try_retrain = 0\n",
    "    netD.eval()\n",
    "        \n",
    "\n",
    "    if len(under50z_list) == 0 :\n",
    "        num_of_under50 = 0\n",
    "        num_of_first_under50 = 0\n",
    "    else:\n",
    "        under50z_set = torch.cat(under50z_list)\n",
    "        num_of_under50 = under50z_set.size(0)\n",
    "        num_of_first_under50 = num_of_under50\n",
    "        \n",
    "\n",
    "    #another chance part\n",
    "    '''\n",
    "    while try_retrain < config.try_div_chance :\n",
    "        print(try_retrain, under50z_set.shape, num_of_under50/50000)\n",
    "        under50z_dataset = torch.utils.data.TensorDataset(under50z_set)\n",
    "        under50z_dataloder = torch.utils.data.DataLoader(under50z_dataset,batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "        under50z_list = []\n",
    "\n",
    "        for data in under50z_dataloder : \n",
    "            z = data[0].to(device)\n",
    "            netG.zero_grad()\n",
    "            batch_size = z.size(0)\n",
    "            label = torch.full((batch_size,), real_label,\n",
    "                           dtype=z.dtype, device=device)\n",
    "\n",
    "            fake = netG(z)\n",
    "            output = netD(fake)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            fake = netG(z)\n",
    "            output = netD(fake)\n",
    "            condition_under50 = output < 0.5\n",
    "            under50z_list.append( z[condition_under50].detach().cpu() )\n",
    "\n",
    "        try_retrain+=1\n",
    "\n",
    "        if len(under50z_list) == 0 :\n",
    "            num_of_under50 = 0\n",
    "            break\n",
    "        else:\n",
    "            under50z_set = torch.cat(under50z_list)\n",
    "            num_of_under50 = under50z_set.size(0)\n",
    "     '''\n",
    "\n",
    "    #keep try G part\n",
    "    keep_try = True\n",
    "    while (1-num_of_under50/50000) < config.keep_try_over : \n",
    "        print(\"keep try:\", try_retrain, (1-num_of_under50/50000), \"<\",config.keep_try_over)\n",
    "        num_of_under50 = 0\n",
    "        \n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            batch_size = data[0].size(0)\n",
    "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "            label = torch.full((batch_size,), real_label,\n",
    "                           dtype=real_cpu.dtype, device=device)\n",
    "            fake = netG(noise)\n",
    "            fake2 = netG(noise + config.z_add)\n",
    "\n",
    "            output = netD(fake)\n",
    "\n",
    "            loss_ds = torch.mean(torch.abs(fake - fake2))\n",
    "\n",
    "            errG = criterion(output, label) - config.lambda_diverse * loss_ds\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimizerG.step()\n",
    "\n",
    "            fake = netG(noise)\n",
    "            output = netD(fake)\n",
    "            condition_under50 = output < 0.5\n",
    "            num_of_under50 += int(torch.sum(condition_under50).detach().cpu())\n",
    "\n",
    "        try_retrain += 1\n",
    "    else :\n",
    "        print(\"keep try:\", try_retrain, (1-num_of_under50/50000), \"<\",config.keep_try_over,\"(pass)\")\n",
    "        \n",
    "\n",
    "    netD.train()\n",
    "    num_of_still_under50 = torch.cat(under50z_list).size(0)\n",
    "\n",
    "    if config.report_every > 0 and epoch % config.report_every == 0:\n",
    "        fake = netG(fixed_noise)\n",
    "        vutils.save_image(fake.detach(),\n",
    "            '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "            normalize=True)\n",
    "\n",
    "        fake2 = netG(fixed_noise + config.z_add)\n",
    "        vutils.save_image(fake2.detach(),\n",
    "            '%s/fake2_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "            normalize=True)\n",
    "        \n",
    "        fake_np = vutils.make_grid(fake.detach().cpu(), nrow=32).permute(1,2,0).numpy()\n",
    "        fake2_np = vutils.make_grid(fake2.detach().cpu(), nrow=32).permute(1,2,0).numpy()\n",
    "        \n",
    "        netG = netG.to('cpu')\n",
    "        netD = netD.to('cpu')\n",
    "        \n",
    "        lpips_model.to(device)\n",
    "        ex_d = lpips_model.forward(fake, fake2).mean()\n",
    "        lpips_model.to('cpu')\n",
    "        \n",
    "        inception_model_score.model_to(device)\n",
    "\n",
    "        #generate fake images info\n",
    "        inception_model_score.lazy_forward(batch_size=64, device=device, fake_forward=True)\n",
    "        inception_model_score.calculate_fake_image_statistics()\n",
    "        metrics = inception_model_score.calculate_generative_score()\n",
    "        inception_model_score.clear_fake()\n",
    "\n",
    "        #onload all GAN model to cpu and offload inception model to gpu\n",
    "        inception_model_score.model_to('cpu')\n",
    "        netG = netG.to(device)\n",
    "        netD = netD.to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f, DivLoss : %.4f'\n",
    "          % (epoch, opt.niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, loss_ds.item()))\n",
    "        \n",
    "        print(\"\\t\\tFID : %.4f, IS_f : %.4f, P : %.4f, R : %.4f, D : %.4f, C : %.4f, LPIPS : %.4f, \n",
    "              %(metrics['fid'], metrics['fake_is'], metrics['precision'], \n",
    "                metrics['recall'], metrics['density'], metrics['coverage'], ex_d))\n",
    "        \n",
    "       \n",
    "        vutils.save_image(real_cpu,\n",
    "                '%s/real_samples.png' % opt.outf,\n",
    "                normalize=True)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\" : epoch,\n",
    "            \"Loss_D\": errD.item(),\n",
    "            \"Loss_G\": errG.item(),\n",
    "            \"D(real)\": D_x,\n",
    "            \"D(G(z))-before D train\": D_G_z1,\n",
    "            \"D(G(z))-after D train\": D_G_z2,\n",
    "            \"DivLoss\" : loss_ds.item(),\n",
    "            \"fid\" : metrics['fid'],\n",
    "            'fake_is':metrics['fake_is'],\n",
    "            \"precision\":metrics['precision'],\n",
    "            \"recall\":metrics['recall'],\n",
    "            \"density\":metrics['density'],\n",
    "            \"coverage\":metrics['coverage'],\n",
    "            \"G(z) \" : [wandb.Image(fake_np, caption='fixed z image')],\n",
    "            \"G(z + div_add) \" : [wandb.Image(fake2_np, caption='fixed z + 1e-6 image')],\n",
    "            'num_of_still_under50' : num_of_still_under50,\n",
    "            'num_of_first_under50' : num_of_first_under50,\n",
    "            'LPIPS' : ex_d,\n",
    "            'try_retrain' : try_retrain\n",
    "        })\n",
    "\n",
    "        if opt.dry_run:\n",
    "            break\n",
    "    # do checkpointing\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        vutils.save_image(fake.detach(),\n",
    "                '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "                normalize=True)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad70f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stylegan2",
   "language": "python",
   "name": "stylegan2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
